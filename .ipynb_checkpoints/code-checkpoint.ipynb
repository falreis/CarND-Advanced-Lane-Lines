{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Lines\n",
    "----\n",
    "\n",
    "----\n",
    "In this project, your goal is to write a software pipeline to identify the lane boundaries in a video, but the main output or product we want you to create is a detailed writeup of the project.  Check out the [writeup template](https://github.com/udacity/CarND-Advanced-Lane-Lines/blob/master/writeup_template.md) for this project and use it as a starting point for creating your own writeup.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "from scipy.stats import linregress\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Helper Classes\n",
    "\n",
    "Helper classes to receive characteristics for each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "print('Class line OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions. Some of them are based on the first line lanes \n",
    ":)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of Interests (ROI) Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region of interests\n",
    "CONST_X_LEFT_TOP = 550\n",
    "CONST_X_LEFT_BOTTOM = 270\n",
    "CONST_X_RIGHT_BOTTOM = 1100\n",
    "CONST_Y_TOP = 450\n",
    "CONST_Y_BOTTOM = 660\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img) #defining a blank mask to start with\n",
    "    \n",
    "    if len(img.shape) > 2: #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color) #filling pixels inside the polygon with the fill color    \n",
    "    return cv2.bitwise_and(img, mask)\n",
    "\n",
    "def vertices_to_crop(img):\n",
    "    imshape = img.shape\n",
    "    left_top = (CONST_X_LEFT_TOP,CONST_Y_TOP)\n",
    "    left_bot = (CONST_X_LEFT_BOTTOM, CONST_Y_BOTTOM)\n",
    "    right_top = ((imshape[1]-CONST_X_LEFT_TOP), CONST_Y_TOP)\n",
    "    right_bot = (CONST_X_RIGHT_BOTTOM, CONST_Y_BOTTOM)\n",
    "    vertices = np.array([[left_bot, left_top, right_top, right_bot]], dtype=np.int32)\n",
    "    return vertices\n",
    "\n",
    "print('Region of Interests functions OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color functions\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def hls_color(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "def binary_s_channel(img, thresh=(90,255)):\n",
    "    S = img[:,:,2]\n",
    "    binary = np.zeros_like(S)\n",
    "    binary[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    return binary\n",
    "\n",
    "def sobel(img, sobel_kernel=3, dir_thresh=(0, np.pi/2), mag_thresh=(0, 255), abs_thresh=(0,255)):\n",
    "    gray = grayscale(img)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    #abs sobel\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    scaledx = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    scaledy = np.uint8(255*abs_sobely/np.max(abs_sobely))\n",
    "    \n",
    "    #direction sobel\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    arctan = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    #gradmag sobel\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    \n",
    "    #combined direction sobel with gradmag sobel\n",
    "    sxbinary = np.zeros_like(arctan)\n",
    "    sxbinary[(arctan >= dir_thresh[0]) & (arctan <= dir_thresh[1]) & \n",
    "             (gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1]) &\n",
    "             (scaledx >= abs_thresh[0]) & (scaledx <= abs_thresh[1]) &\n",
    "             (scaledy >= abs_thresh[0]) & (scaledy <= abs_thresh[1])\n",
    "            ] = 1\n",
    "    \n",
    "    return sxbinary\n",
    "\n",
    "print('Color functions OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera calibration functions\n",
    "CONST_CORNERS_HORIZ = 9\n",
    "CONST_CORNERS_VERT = 6\n",
    "\n",
    "def calibrate_camera(gray_image, objpoints, imgpoints):\n",
    "    return cv2.calibrateCamera(objpoints, imgpoints, gray_image.shape[::-1], None, None)\n",
    "\n",
    "def undistort(chess_image, gray_image, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = calibrate_camera(gray_image, objpoints, imgpoints)\n",
    "    return cv2.undistort(chess_image, mtx, dist, None, mtx)\n",
    "\n",
    "def chessboard(img, corners=(CONST_CORNERS_HORIZ,CONST_CORNERS_VERT)):\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    objp = np.zeros((corners[0]*corners[1], 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:corners[0], 0:corners[1]].T.reshape(-1,2)\n",
    "\n",
    "    #find chessboard corners\n",
    "    gray = grayscale(img)\n",
    "    ret, chess_corners = cv2.findChessboardCorners(gray, (corners[0], corners[1]), None)\n",
    "\n",
    "    #if the chessboard was found\n",
    "    if ret == True:\n",
    "        imgpoints.append(chess_corners)\n",
    "        objpoints.append(objp)\n",
    "        chess_image = cv2.drawChessboardCorners(img, (corners[0], corners[1]), chess_corners, ret)\n",
    "    else:\n",
    "        chess_image = None\n",
    "    \n",
    "    return ret, chess_image, objpoints, imgpoints\n",
    "\n",
    "def calibrate_chess(img):\n",
    "    corners = [CONST_CORNERS_HORIZ, CONST_CORNERS_VERT]\n",
    "    ret, chess_image, objpoints, imgpoints = chessboard(img)\n",
    "\n",
    "    #Different number of corners (try other pattern)!\n",
    "    if ret == False:\n",
    "        corners = [9, 5]\n",
    "        ret, chess_image, objpoints, imgpoints = chessboard(img, corners)\n",
    "    if ret == False:\n",
    "        corners = [8, 6]\n",
    "        ret, chess_image, objpoints, imgpoints = chessboard(img, corners)\n",
    "\n",
    "    #undistort image\n",
    "    if ret == True:\n",
    "        gray_img = grayscale(img)\n",
    "        undist_img = undistort(chess_image, gray_img, objpoints, imgpoints)\n",
    "        ret = True\n",
    "    else:\n",
    "        ret = False\n",
    "        undist_img = None\n",
    "        corners = None\n",
    "        \n",
    "    return ret, undist_img, corners\n",
    "\n",
    "def warped(img, calibrate=True, undist_img=None, corners=None):\n",
    "    if calibrate == True:\n",
    "        ret, undist_img, corners = calibrate_chess(img.copy())\n",
    "    else:\n",
    "        ret = True\n",
    "    \n",
    "    if ret == True:\n",
    "        nx = corners[0]\n",
    "        ny = corners[1]\n",
    "        gray_img = grayscale(img)\n",
    "        ret, chess_corners = cv2.findChessboardCorners(gray_img, (nx,ny), None)\n",
    "\n",
    "        if ret == True:\n",
    "            offset = 100 # offset for dst points\n",
    "            img_size = (gray_img.shape[1], gray_img.shape[0])\n",
    "            src = np.float32([chess_corners[0], chess_corners[nx-1], chess_corners[-1], chess_corners[-nx]])\n",
    "            dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                         [img_size[0]-offset, img_size[1]-offset], \n",
    "                                         [offset, img_size[1]-offset]])\n",
    "            M = cv2.getPerspectiveTransform(src, dst)\n",
    "            warp_img = cv2.warpPerspective(undist_img, M, img_size)\n",
    "        else:\n",
    "            warp_img = None\n",
    "    else:\n",
    "        warp_img = None\n",
    "        \n",
    "    return ret, warp_img\n",
    "\n",
    "print('Camera calibration functions OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny, Gaussian Blur, and Hough Transform Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#canny, gaussian blur, and hough transform\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def draw_lines(img, lines, color=[255,0,0], thickness=10):\n",
    "    left_line = []\n",
    "    right_line = []\n",
    "    middle_x = img.shape[1] / 2\n",
    "    \n",
    "    '''\n",
    "    Calculate slope of points and create the lines\n",
    "      - Reject points on the left side of the pictures if the slope is negative\n",
    "      - Reject points on the right side of the pictures if the slope is positive\n",
    "    '''\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            if slope > 0: #right\n",
    "                #reject entry if slope is positive and (x1 or x2) < (middle of image)\n",
    "                if x1 > middle_x and x2 > middle_x: \n",
    "                    right_line.append([x1,y1]) \n",
    "                    right_line.append([x2,y2])\n",
    "            elif slope < 0: #left\n",
    "                #reject entry if slope is negative and (x1 or x2) > (middle of image)\n",
    "                if x1 < middle_x and x1 < middle_x:\n",
    "                    left_line.append([x1,y1]) \n",
    "                    left_line.append([x2,y2])\n",
    "    \n",
    "    #plot left line\n",
    "    ldata = np.array(left_line)\n",
    "    if len(ldata) > 0:\n",
    "        lfit = np.polyfit(ldata[:,0], ldata[:,1] , 1)\n",
    "        l1z = np.poly1d(lfit)\n",
    "\n",
    "        lx1 = CONST_X_LEFT_BOTTOM\n",
    "        lx2 = CONST_X_LEFT_TOP\n",
    "        cv2.line(img, (lx1, int(l1z(lx1))), (lx2, int(l1z(lx2))), color, thickness, 4)\n",
    "    \n",
    "    #plot right line\n",
    "    rdata = np.array(right_line)\n",
    "    if len(rdata) > 0:\n",
    "        rfit = np.polyfit(rdata[:,0], rdata[:,1] ,1)\n",
    "        r1z = np.poly1d(rfit)\n",
    "\n",
    "        rx1 = img.shape[1] - CONST_X_RIGHT_BOTTOM\n",
    "        rx2 = img.shape[1] - CONST_X_LEFT_TOP\n",
    "        cv2.line(img, (rx1, int(r1z(rx1))), (rx2, int(r1z(rx2))), color, thickness, 4)\n",
    "\n",
    "def hough_lines(base_img, canny_img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    lines = cv2.HoughLinesP(canny_img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    #line_img = np.zeros((canny_img.shape[0], canny_img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(base_img, lines)\n",
    "    return base_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "def weighted_img(img, initial_img, α=0.4, β=0.6, λ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "print('Hough functions OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Image (Hough) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process image (hough)\n",
    "def process_image(image):\n",
    "    gray = grayscale(image)\n",
    "    base_image = np.copy(image)\n",
    "\n",
    "    # Define a kernel size and apply Gaussian smoothing\n",
    "    kernel_size = 5\n",
    "    blur_gray = gaussian_blur(gray, kernel_size)\n",
    "\n",
    "    # Define our parameters for Canny and apply\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = canny(blur_gray, low_threshold, high_threshold) \n",
    "\n",
    "    # This time we are defining a four sided polygon to mask\n",
    "    vertices = vertices_to_crop(image)\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "    \n",
    "    # Define the Hough transform parameters\n",
    "    # Make a blank the same size as our image to draw on\n",
    "    rho = 2 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 10 # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 15 # minimum number of pixels making up a line\n",
    "    max_line_gap = 10 # maximum gap in pixels between connectable line segments    \n",
    "    \n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    \n",
    "    hough_image = hough_lines(image, masked_edges, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "        \n",
    "    # Draw the lines on the edge image\n",
    "    w_image = weighted_img(hough_image, base_image)\n",
    "    \n",
    "    return w_image\n",
    "\n",
    "print('Process images function OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_HISTOGRAM_MARGIN = 100\n",
    "\n",
    "def fit_histogram(img):\n",
    "    # Assuming you have created a warped binary image called \"img\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = CONST_HISTOGRAM_MARGIN\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high), (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high), (0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return out_img, left_fit, right_fit, left_lane_inds, right_lane_inds, nonzerox, nonzeroy\n",
    "\n",
    "def fit_continuous(img):\n",
    "    hist_img, left_fit, right_fit, left_lane, right_lane, nonzerox, nonzeroy = fit_histogram(img)\n",
    "    \n",
    "    # Assume you now have a new warped binary image \n",
    "    # from the next frame of video (also called \"binary_warped\")\n",
    "    # It's now much easier to find line pixels!\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = CONST_HISTOGRAM_MARGIN\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "        left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "        left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "        right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "        right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    return left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy\n",
    "\n",
    "def plot_histogram(img):\n",
    "    hist_img, left_fit, right_fit, left_lane_inds, right_lane_inds, nonzerox, nonzeroy = fit_histogram(img)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    hist_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    hist_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    plt.imshow(hist_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    \n",
    "    return ploty, left_fitx, right_fitx\n",
    "    \n",
    "def plot_continuous(img):\n",
    "    #fit plotting\n",
    "    left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy = fit_continuous(img.copy())\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-CONST_HISTOGRAM_MARGIN, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+CONST_HISTOGRAM_MARGIN, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-CONST_HISTOGRAM_MARGIN, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+CONST_HISTOGRAM_MARGIN, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    plt.imshow(result)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "\n",
    "print('Histogram functions OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Curvature and Relative Positions Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/1280 # meters per pixel in x dimension\n",
    "\n",
    "def curvature(left_fitx, right_fitx, ploty):\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "def relative_position(mean_fitx):\n",
    "    return ((1280/2)-mean_fitx)*xm_per_pix\n",
    "\n",
    "def write_text(img, curve_rad, position):\n",
    "    #if radius > 2000m (arbitrary value), we have a straight\n",
    "    if curve_rad <= 2000.: \n",
    "        txt_curve = \"Left Radius:\" + str('{0:.2f}'.format(curve_rad)) + \"m\"\n",
    "    else:\n",
    "        txt_curve = \"Left Radius: -\"\n",
    "        \n",
    "    txt_pos = \"Relative Pos: \" + str('{0:.2f}'.format(position)) + \"m\"\n",
    "    \n",
    "    draw_img = cv2.putText(img=np.copy(img)\n",
    "                               , text=(txt_curve + \" | \" + txt_pos)\n",
    "                               , org=(10,50)\n",
    "                               , fontFace=2\n",
    "                               , fontScale=1.5\n",
    "                               , color=(255,255,255)\n",
    "                               , thickness=2\n",
    "    )\n",
    "    return draw_img\n",
    "\n",
    "print('Calculate curvature function OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warp Transform Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_src = np.float32(\n",
    "    [[ 270, 700],\n",
    "     [ 550, 450],\n",
    "     [ 730, 450],\n",
    "     [1100, 700]]\n",
    ")\n",
    "\n",
    "vertices_dst = np.float32(\n",
    "    [[ 550, 700],\n",
    "     [ 550, 450],\n",
    "     [ 730, 450],\n",
    "     [ 730, 700]]\n",
    ")\n",
    "\n",
    "CONST_VERT_X1 = 550\n",
    "CONST_VERT_X2 = 750\n",
    "CONST_VERT_Y1 = 500\n",
    "CONST_VERT_Y2 = 700\n",
    "\n",
    "vertices_y_top = 520\n",
    "\n",
    "def warp_transform(img, inv=False):\n",
    "    #compute perspective, transform M\n",
    "    if inv == False:\n",
    "        M = cv2.getPerspectiveTransform(vertices_src, vertices_dst)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(vertices_dst, vertices_src)\n",
    "\n",
    "    return cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "print('Warp transform functions OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_PIPELINE_S_CHANNEL_THRESH = (180,255)\n",
    "\n",
    "def pipeline(img):\n",
    "    #convert to HSV color and define region of interest (ROI)\n",
    "    hsl_img = hls_color(img) #convert to HSV color\n",
    "    vertices = vertices_to_crop(hsl_img) #define region of interests\n",
    "    roi_img = region_of_interest(hsl_img, vertices)\n",
    "\n",
    "    s_img = binary_s_channel(roi_img, CONST_PIPELINE_S_CHANNEL_THRESH) #process s channel\n",
    "\n",
    "    #warp original image and s channel image\n",
    "    warp_s = warp_transform(s_img)\n",
    "    warp_orig = warp_transform(img)\n",
    "    warp_crop = warp_orig[CONST_VERT_Y1:CONST_VERT_Y2, CONST_VERT_X1:CONST_VERT_X2]  #new TODO\n",
    "\n",
    "    #apply fit continuous in the s channel image\n",
    "    left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy = fit_continuous(warp_s)\n",
    "    \n",
    "    #draw green area over the warp image ()\n",
    "    shape_x = warp_orig.shape[0]\n",
    "    shape_y = warp_orig.shape[1]\n",
    "    \n",
    "    green_warp = warp_orig\n",
    "    for i in range(1, warp_crop.shape[0]):\n",
    "        k = i + vertices_y_top\n",
    "        for j in range(int(left_fitx[k]), int(right_fitx[k])):\n",
    "            if k < shape_x and j < shape_y:\n",
    "                green_warp[k,j,0] = 0.\n",
    "                green_warp[k,j,2] = 0.\n",
    "\n",
    "    #unwarp image\n",
    "    green_persp = warp_transform(green_warp,True)\n",
    "\n",
    "    #merge unwarp image with the original image\n",
    "    green_persp[0:vertices_y_top, :] = img[0:vertices_y_top, :]\n",
    "    \n",
    "    #write curvature and distance to the center\n",
    "    ploty = np.linspace(0, green_persp.shape[0]-1, green_persp.shape[0] )\n",
    "    left_curverad, right_curverad = curvature(left_fitx, right_fitx, ploty)\n",
    "    pos = relative_position(np.mean(left_fitx)) #use continuous track line, to increase accuracy\n",
    "    \n",
    "    final_img = write_text(green_persp, left_curverad, pos) #use continuous track line, to increase accuracy\n",
    "    \n",
    "    #return final image\n",
    "    return final_img\n",
    "\n",
    "print('Pipeline OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = random.randint(1,20)\n",
    "img_name = 'camera_cal/calibration' + str(2) + '.jpg' #img_index\n",
    "print(img_name)\n",
    "\n",
    "cal_image = mpimg.imread(img_name)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(cal_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find chessboard corner\n",
    "ret, chess_image, objpoints, imgpoints = chessboard(cal_image.copy())\n",
    "\n",
    "if ret == False:\n",
    "    print('Different number of corners!')\n",
    "    ret, chess_image, objpoints, imgpoints = chessboard(cal_image.copy(), [9, 5])\n",
    "\n",
    "#plot image\n",
    "if ret == True:\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(chess_image)\n",
    "else:\n",
    "    print('Corners not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undistort image\n",
    "if ret == True:\n",
    "    gray_img = grayscale(cal_image.copy())\n",
    "    r, mtx, dist, rvecs, tvecs = calibrate_camera(gray_img, objpoints, imgpoints)\n",
    "    undist_img = undistort(chess_image, gray_img, objpoints, imgpoints)\n",
    "    \n",
    "    #plot image\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(undist_img)\n",
    "else:\n",
    "    print('Corners not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unwarped images\n",
    "if ret == True:\n",
    "    ret, warp_img = warped(cal_image.copy())\n",
    "        \n",
    "    #plot image\n",
    "    if ret == True:\n",
    "        plt.figure(figsize=(7,7))\n",
    "        plt.imshow(warp_img)\n",
    "else:\n",
    "    print('Corners not found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONST_INPUT_CALIBRAT_PATH = \"camera_cal/\"\n",
    "CONST_OUTPUT_CALIBRAT_PATH = \"output_images/\"\n",
    "\n",
    "img_paths = os.listdir(CONST_INPUT_CALIBRAT_PATH)\n",
    "\n",
    "ar_mtx = []\n",
    "ar_dist = []\n",
    "\n",
    "for img_name in img_paths:\n",
    "    image = mpimg.imread(CONST_INPUT_CALIBRAT_PATH + img_name)\n",
    "    corners = [9,6]\n",
    "    \n",
    "    #find chessboard\n",
    "    ret, chess_image, objpoints, imgpoints = chessboard(image)\n",
    "    if ret == False: #Different number of corners!\n",
    "        corners = [9,5]\n",
    "        ret, chess_image, objpoints, imgpoints = chessboard(cal_image.copy(), [9, 5])\n",
    "    \n",
    "    #chessboard ok\n",
    "    if ret == True:\n",
    "        gray_img = grayscale(image)\n",
    "        r, mtx, dist, rvecs, tvecs = calibrate_camera(gray_img, objpoints, imgpoints)\n",
    "        ar_mtx.append(mtx)\n",
    "        ar_dist.append(dist)\n",
    "    \n",
    "        undist_img = undistort(chess_image, gray_img, objpoints, imgpoints)\n",
    "        ret, warp_img = warped(image, False, undist_img, corners)\n",
    "    \n",
    "    #save image\n",
    "    if ret == True:\n",
    "        plt.imshow(warp_img)\n",
    "        plt.savefig(CONST_OUTPUT_CALIBRAT_PATH + img_name)\n",
    "        \n",
    "    print(img_name)\n",
    "    \n",
    "mtx = np.mean(ar_mtx)\n",
    "dist = np.mean(ar_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Images\n",
    "\n",
    "Build your pipeline to work on the images in the directory \"test_images\"  \n",
    "**You should make sure your pipeline works well on these images before you try the videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img = mpimg.imread('test_images/test2.jpg')\n",
    "\n",
    "#undistort image\n",
    "image = cv2.undistort(original_img, mtx, dist, None, mtx)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,20))\n",
    "ax1.imshow(original_img)\n",
    "ax2.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #define region of interests (ROI)\n",
    "vertices = vertices_to_crop(image)\n",
    "print(vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw ROI\n",
    "draw_img = cv2.polylines(image.copy(),[vertices],True,(255,0,0), thickness = 10)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to shv color and get region of interests (ROI)\n",
    "hsv_img = hls_color(image.copy()) #convert to HSV color\n",
    "vertices = vertices_to_crop(hsv_img) #define region of interests\n",
    "roi_img = region_of_interest(hsv_img, vertices)\n",
    "\n",
    "print('ROI OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process s channel\n",
    "s_img = binary_s_channel(roi_img.copy(), (180,255)) #process s channel\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(roi_img)\n",
    "ax2.imshow(s_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sobel image\n",
    "sobel_img = sobel(roi_img.copy(), sobel_kernel=7, dir_thresh=(0.5, 1.5), mag_thresh=(80,150), abs_thresh=(80,150))\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(roi_img)\n",
    "ax2.imshow(sobel_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot image histogram (3d - s channel)\n",
    "histogram = np.sum(s_img[s_img.shape[0]//2:,:], axis=0)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(histogram)\n",
    "\n",
    "#plot image histogram (3d - sobel)\n",
    "histogram = np.sum(sobel_img[sobel_img.shape[0]//2:,:], axis=0)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seens like s channel has a better result then sobel image.\n",
    "\n",
    "Keep using s channel.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram image (s channel)\n",
    "ploty, left_fitx, right_fitx = plot_histogram(s_img.copy()) #sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram continuous image\n",
    "plot_continuous(s_img.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Image transform and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warp original image\n",
    "warp_orig = warp_transform(image)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(image)\n",
    "ax2.imshow(warp_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop image\n",
    "warp_crop = warp_orig[CONST_VERT_Y1:CONST_VERT_Y2, CONST_VERT_X1:CONST_VERT_X2]  #new TODO\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(warp_orig)\n",
    "ax2.imshow(warp_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warp s channel image\n",
    "warp_s = warp_transform(s_img)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(s_img)\n",
    "ax2.imshow(warp_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seens that s channel image is more accurate to performe the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot image histogram (3d - s channel)\n",
    "histogram = np.sum(warp_s[warp_s.shape[0]//2:,:], axis=0)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram image\n",
    "ploty, left_fitx, right_fitx = plot_histogram(warp_s.copy()) #sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histogram continuous image\n",
    "plot_continuous(warp_s.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate x and y values for plotting\n",
    "plt.imshow(warp_orig)\n",
    "plt.plot(left_fitx, (np.linspace(0, warp_orig.shape[0]-1, warp_orig.shape[0])), color='red')\n",
    "plt.plot(right_fitx, (np.linspace(0, warp_orig.shape[0]-1, warp_orig.shape[0])), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#light camera vision\n",
    "green_warp = warp_orig.copy()\n",
    "for i in range(1, warp_crop.shape[0]):\n",
    "    k = i + vertices_y_top\n",
    "    for j in range(int(left_fitx[k]), int(right_fitx[k])):\n",
    "        green_warp[k,j,0] = 0.\n",
    "        green_warp[k,j,2] = 0.\n",
    "\n",
    "#green_warp = green_warp[:, min_lfitx:max_rightx]\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green_warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_persp = warp_transform(green_warp,True)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(green_persp)\n",
    "ax2.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine images\n",
    "green_persp[0:vertices_y_top, :] = image[0:vertices_y_top, :]\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(green_persp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print image dimensions\n",
    "left_curverad, right_curverad = curvature(left_fitx, right_fitx, ploty)\n",
    "print(left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Test (Image Directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_INPUT_PIPELINE_PATH = \"test_images/\"\n",
    "CONST_OUTPUT_PIPELINE_PATH = \"output_images/\"\n",
    "\n",
    "img_paths = os.listdir(CONST_INPUT_PIPELINE_PATH)\n",
    "\n",
    "for img_name in img_paths:\n",
    "    original_image = mpimg.imread(CONST_INPUT_PIPELINE_PATH + img_name)\n",
    "    image = cv2.undistort(original_image, mtx, dist, None, mtx)\n",
    "    pipe_img = pipeline(image)\n",
    "    \n",
    "    #save image\n",
    "    plt.imshow(pipe_img)\n",
    "    plt.savefig(CONST_OUTPUT_PIPELINE_PATH + img_name)\n",
    "    print(CONST_INPUT_PIPELINE_PATH + img_name)\n",
    "\n",
    "    \n",
    "'''\n",
    "#test pipeline\n",
    "original_image = mpimg.imread('test_images/test2.jpg')\n",
    "pipe_img = pipeline(original_image)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(original_image)\n",
    "ax2.imshow(pipe_img)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Videos\n",
    "\n",
    "You know what's cooler than drawing lanes over images? Drawing lanes over video!\n",
    "\n",
    "Provided videos: `project_video.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the one with the solid white lane on the right first ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "\n",
    "video_output = 'output_project_video.mp4'\n",
    "\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writeup and Submission\n",
    "\n",
    "If you're satisfied with your video outputs, it's time to make the report writeup in a pdf or markdown file. Once you have this Ipython notebook ready along with the writeup, it's time to submit for review! Here is a [link](https://github.com/udacity/CarND-LaneLines-P1/blob/master/writeup_template.md) to the writeup template file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional Challenge\n",
    "\n",
    "Challenge the others videos.\n",
    "`challenge_video.mp4`\n",
    "`hard_challenge_video.mp4`"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
